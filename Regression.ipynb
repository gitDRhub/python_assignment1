{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.What is Simple Linear Regression?\n",
        "\n",
        "ANS-- Simple Linear Regression is a statistical method used to model the relationship between a single independent variable (X) and a dependent variable (Y) by fitting a straight line through the data points."
      ],
      "metadata": {
        "id": "zjI_T5vWg0bF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "ANS--Linearity: The relationship between X and Y is linear.\n",
        "Independence: Observations are independent of each other.\n",
        "Homoscedasticity: Constant variance of residuals.\n",
        "Normality: Residuals are normally distributed."
      ],
      "metadata": {
        "id": "N5EAmGNug5F2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.What does the coefficient m represent in the equation Y=mX+c?\n",
        "\n",
        "ANS--The coefficient ùëö represents the slope of the line, indicating the change in\n",
        "Y for a one-unit increase in\n",
        "X.\n"
      ],
      "metadata": {
        "id": "u2A7TeyPhKNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.What does the intercept c represent in the equation\n",
        "Y=mX+c?\n",
        "\n",
        "ANS--The intercept \\( c \\) represents the value of \\( Y \\) when \\( X \\) is zero.\n",
        "# New Section"
      ],
      "metadata": {
        "id": "1wMj8qZXiFnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        "The slope \\( m \\) is calculated as:\n",
        "   \\[\n",
        "   m = \\frac{\\text{Cov}(X, Y)}{\\text{Var}(X)}\n",
        "   \\]\n"
      ],
      "metadata": {
        "id": "ELTkGD27iQmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "ANS--The least squares method minimizes the sum of the squared differences between the observed values and the predicted values.\n"
      ],
      "metadata": {
        "id": "7sUbPBpiie_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.How is the coefficient of determination (\\( R^2 \\)) interpreted in Simple Linear Regression?\n",
        "\n",
        " ANS-- ( R^2 \\) indicates the proportion of the variance in the dependent variable  Y that is explained by the independent variable  X .\n"
      ],
      "metadata": {
        "id": "bDExYDTKim74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is Multiple Linear Regression?\n",
        "\n",
        "ANS--Multiple Linear Regression models the relationship between a dependent variable and multiple independent variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "HKalyFHGi9Uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "ANS--   Simple Linear Regression involves one independent variable, while Multiple Linear Regression involves two or more independent variables.\n"
      ],
      "metadata": {
        "id": "0ckxL0DDjGer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "ANS-- Linearity.\n",
        "    - Independence of errors.\n",
        "    - Homoscedasticity.\n",
        "    - Multivariate normality.\n",
        "    - No multicollinearity.\n"
      ],
      "metadata": {
        "id": "KjHmJnoVjNgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "ANS-- Heteroscedasticity occurs when the variance of residuals is not constant, leading to inefficient estimates and unreliable hypothesis tests."
      ],
      "metadata": {
        "id": "WWLDqeRzjT0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "ANS--  - Remove highly correlated predictors.\n",
        "    - Use techniques like Ridge or Lasso Regression.\n",
        "    - Use Principal Component Analysis (PCA).\n"
      ],
      "metadata": {
        "id": "6Iu_P4UCjiIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "ANS-- One-hot encoding.\n",
        "    - Label encoding.\n",
        "    - Binary encoding.\n"
      ],
      "metadata": {
        "id": "iCdyuE4PjqxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "ANS--Interaction terms capture the combined effect of two or more variables on the dependent variable.\n"
      ],
      "metadata": {
        "id": "ADv5PjqTjzNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "In Simple Linear Regression, the intercept represents the value of Y when X is zero. In Multiple Linear Regression, it represents Y when all predictors are zero.\n"
      ],
      "metadata": {
        "id": "dvjQSCewj5YW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "ANS--  The slope quantifies the relationship between an independent variable and the dependent variable, indicating how much Y changes for a unit change in X .\n"
      ],
      "metadata": {
        "id": "HL3cL5B7kDqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "  \n",
        "ANS-- The intercept provides a baseline value of the dependent variable when all predictors are zero.\n"
      ],
      "metadata": {
        "id": "oPGoviqakL_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What are the limitations of using  R^2 as a sole measure of model performance?\n",
        "\n",
        "ANS\n",
        "    - It does not account for model complexity.\n",
        "    - It may give a high value even for overfitted models.\n",
        "    - Adjusted R^2 is a better alternative for multiple predictors.\n"
      ],
      "metadata": {
        "id": "83lJY-uFkSBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How would you interpret a large standard error for a regression coefficient?\n",
        "  \n",
        "ANS--A large standard error indicates that the coefficient estimate is less precise, leading to wider confidence intervals"
      ],
      "metadata": {
        "id": "dpAzt2QlkZWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "ANS-- Heteroscedasticity is identified when residuals display a funnel-shaped pattern in plots. Addressing it ensures more reliable hypothesis tests and confidence intervals.\n"
      ],
      "metadata": {
        "id": "XqFu0XZ9kfyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What does it mean if a Multiple Linear Regression model has a high \\( R^2 \\) but low adjusted \\( R^2 \\)?\n",
        "\n",
        "ANS--This suggests that adding more predictors does not improve the model significantly and may lead to overfitting.\n"
      ],
      "metadata": {
        "id": "uD3xL6Rckkg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "ANS-- Scaling ensures that predictors are on the same scale, which is essential for interpreting coefficients and improving numerical stability.\n"
      ],
      "metadata": {
        "id": "LKkzfiDjkrt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is polynomial regression?\n",
        "\n",
        "ANS-- Polynomial regression models the relationship between the dependent variable and independent variable(s) as an nth-degree polynomial.\n"
      ],
      "metadata": {
        "id": "SB5Cbfo2kvbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "24. How does polynomial regression differ from linear regression?\n",
        "\n",
        "\n",
        "ANS--While linear regression models a straight-line relationship, polynomial regression fits a curve to capture non-linear relationships.\n",
        "\n"
      ],
      "metadata": {
        "id": "d6Xr1sIuk07L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. When is polynomial regression used?\n",
        "    \n",
        "  ANS--When the relationship between variables is non-linear.\n"
      ],
      "metadata": {
        "id": "P3PnXSSak6No"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. *What is the general equation for polynomial regression?*\n",
        "    \n",
        " ANS-- \\[\n",
        "  Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\dots + \\beta_nX^n\n",
        "  \\]\n"
      ],
      "metadata": {
        "id": "DwzILQRMk-gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. *Can polynomial regression be applied to multiple variables?*\n",
        "  \n",
        "  ANS--Yes, polynomial terms can be added for multiple variables and their interactions.\n"
      ],
      "metadata": {
        "id": "FnpZfYHdlFO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "28. What are the limitations of polynomial regression?\n",
        "  \n",
        "ANS  - Prone to overfitting for high-degree polynomials.\n",
        "    - Sensitive to outliers.\n",
        "    - May lack interpretability.\n"
      ],
      "metadata": {
        "id": "KtQA4tLPlIJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "    \n",
        "  ANS- Cross-validation.\n",
        "    - Adjusted \\( R^2 \\).\n",
        "    - Mean Squared Error (MSE).\n"
      ],
      "metadata": {
        "id": "P1_JUx1DlL4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Why is visualization important in polynomial regression?\n",
        "  \n",
        "  ANS--Visualization helps assess how well the model fits the data and identify potential overfitting or underfitting.\n"
      ],
      "metadata": {
        "id": "CDe2pHbNlREh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "31. How is polynomial regression implemented in Python?\n",
        "  \n",
        "  ANS- Using libraries like NumPy, Scikit-learn, or Statsmodels with steps such as:\n",
        "    - Generating polynomial features with PolynomialFeatures.\n",
        "    - Fitting the model using LinearRegression.\n"
      ],
      "metadata": {
        "id": "d_xi253KlZ8-"
      }
    }
  ]
}